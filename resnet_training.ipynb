{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Print working directory\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160*8)),  # Resize to 80x(80*8)\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "data_dir = \"datafolder\"\n",
    "train_dir = os.path.join(data_dir, \"frames_no_bg_dropout_train\")\n",
    "test_dir = os.path.join(data_dir, \"frames_no_bg_dropout_test\")\n",
    "\n",
    "# Print dataset directories\n",
    "print(f\"Train dataset directory: {train_dir}\")\n",
    "print(f\"Test dataset directory: {test_dir}\")\n",
    "\n",
    "# Check if directories exist\n",
    "if not os.path.exists(train_dir):\n",
    "    print(f\"Train directory does not exist: {train_dir}\")\n",
    "if not os.path.exists(test_dir):\n",
    "    print(f\"Test directory does not exist: {test_dir}\")\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how many positive samples and negative samples are in the datasets\n",
    "def count_samples(loader):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for data, target in loader:\n",
    "        pos += target.sum()\n",
    "        neg += (1 - target).sum()\n",
    "    return pos, neg\n",
    "\n",
    "\n",
    "train_pos, train_neg = count_samples(train_loader)\n",
    "test_pos, test_neg = count_samples(test_loader)\n",
    "\n",
    "print(f\"Train dataset: {train_pos} positive samples, {train_neg} negative samples\")\n",
    "print(f\"Test dataset: {test_pos} positive samples, {test_neg} negative samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def show_sample_images(dataset, num_samples=10):\n",
    "    indices = random.sample(range(len(dataset)), num_samples)\n",
    "    fig, axes = plt.subplots(num_samples, 1, figsize=(5, 15))\n",
    "    for i, idx in enumerate(indices):\n",
    "        image, label = dataset[idx]\n",
    "        image = image.permute(1, 2, 0)  # Move channel dimension to the end\n",
    "        image = image * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])  # Denormalize\n",
    "        image = image.numpy()\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].set_title(f\"Label: {label}\")\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Show sample images from the training dataset\n",
    "show_sample_images(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10, writer=None):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update metrics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "        if writer:\n",
    "            writer.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
    "            writer.add_scalar(\"Accuracy/train\", epoch_acc, epoch)\n",
    "            writer.flush()\n",
    "\n",
    "    if writer:\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load pretrained ResNet\n",
    "model = models.resnet18(pretrained=True)  # Use ResNet18; you can also choose ResNet50\n",
    "num_features = model.fc.in_features  # Number of features in the final layer\n",
    "model.fc = nn.Linear(num_features, 2)  # Modify the final layer to output 2 classes (good/bad)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "writer = SummaryWriter(\"runs/golf_swing_classification\")\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=10, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"golf_swing_classification.pth\")\n",
    "\n",
    "# Test the model\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {correct / total:.4f}\")\n",
    "\n",
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, HiResCAM, GradCAMElementWise, GradCAMPlusPlus, AblationCAM, ScoreCAM, LayerCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "state_dict = torch.load(\"golf_swing_classification.pth\")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Generate Grad-CAM visualizations\n",
    "target_layer = [model.layer4[-1]]\n",
    "# target_layer = [model.layer4[1].conv2]\n",
    "\n",
    "\n",
    "def generate_gradcam_visualizations(model, dataloader, target_layers, device):\n",
    "    cam = GradCAMElementWise(model=model, target_layers=target_layers)\n",
    "    img_count = 0\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        predicted_classes = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        for i in range(len(images)):\n",
    "            targets = [ClassifierOutputTarget(predicted_classes[i].item())]\n",
    "            grayscale_cam = cam(input_tensor=images[i].unsqueeze(0), targets=targets)\n",
    "\n",
    "            img = images[i].cpu().numpy().transpose(1, 2, 0)\n",
    "            img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "            img = np.clip(img, 0, 1)\n",
    "            \n",
    "            visualization = show_cam_on_image(img, grayscale_cam[0], use_rgb=True)\n",
    "            cv2.imwrite(f'resnet_gradcam_elementwise_vis_dropout/gradcam_visualization_{img_count}.jpg', visualization)\n",
    "            img_count += 1\n",
    "\n",
    "generate_gradcam_visualizations(model, test_loader, target_layer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
